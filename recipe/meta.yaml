{% set version = "0.1.96" %}

package:
  name: sentencepiece-split
  version: {{ version }}

source:
  url: https://github.com/google/sentencepiece/archive/v{{ version }}.tar.gz
  sha256: 5198f31c3bb25e685e9e68355a3bf67a1db23c9e8bdccc33dc015f496a44df7a

build:
  number: 1

requirements:
  build:
    - {{ compiler('cxx') }}

outputs:
  - name: libsentencepiece
    script: build-lib.sh   # [unix]
    script: build-lib.bat  # [win]
    build:
      run_exports:
        # not clear what ABI-compatibility of sentencepiece versions are;
        # for now, use same version at run & build time
        - libsentencepiece ={{ version }}
    requirements:
      build:
        - cmake
        - {{ compiler('cxx') }}
        - gperftools  # [unix]
        - make
        - pkg-config
      host:
        - abseil-cpp
        - libprotobuf
        - pthreads-win32  # [win]

    test:
      commands:
        {% for each_lib in ["sentencepiece", "sentencepiece_train"] %}
        # presence of shared libraries
        - test -f $PREFIX/lib/lib{{ each_lib }}.so              # [linux]
        - test -f $PREFIX/lib/lib{{ each_lib }}.dylib           # [osx]
        - if not exist %LIBRARY_BIN%\{{ each_lib }}.dll exit 1  # [win]
        - if not exist %LIBRARY_LIB%\{{ each_lib }}.lib exit 1  # [win]

        # absence of static libraries
        - test ! -f $PREFIX/lib/lib{{ each_lib }}.a             # [unix]
        {% endfor %}

        # headers
        {% for each_header in ["sentencepiece_processor.h", "sentencepiece_trainer.h"] %}
        - test -f $PREFIX/include//{{ each_header }} || (echo "{{ each_header }} not found" && exit 1)  # [unix]
        - if not exist %LIBRARY_INC%\\{{ each_header }} exit 1                                          # [win]
        {% endfor %}

        # binaries
        {% for each_bin in ["decode", "encode", "export_vocab", "normalize", "train"] %}
        - spm_{{ each_bin }} --help
        {% endfor %}

  - name: sentencepiece
    script: build-pkg.sh   # [unix]
    script: build-pkg.bat  # [win]
    requirements:
      build:
        - python                                 # [build_platform != target_platform]
        - cross-python_{{ target_platform }}     # [build_platform != target_platform]
        - {{ compiler('cxx') }}
        - pkg-config
      host:
        - pip
        - python
        - {{ pin_subpackage('libsentencepiece', exact=True) }}
      run:
        - python
        - {{ pin_subpackage('libsentencepiece', exact=True) }}

    test:
      imports:
        - sentencepiece
      requires:
        - pip
        - pytest
      source_files:
        - python/test
        - data
      commands:
        - pip check
        # upstream test suite expects to be run from PKG_ROOT/python
        - cd python && pytest test

about:
  home: "https://github.com/google/sentencepiece/"
  license: Apache-2.0
  license_family: Apache
  license_file: LICENSE
  summary: Unsupervised text tokenizer for Neural Network-based text generation.
  description: |
    SentencePiece is an unsupervised text tokenizer and detokenizer mainly for
    Neural Network-based text generation systems where the vocabulary size is
    predetermined prior to the neural model training.

    SentencePiece implements subword units (e.g., byte-pair-encoding (BPE)
    [[Sennrich et al.](http://www.aclweb.org/anthology/P16-1162)]) and unigram
    language model [[Kudo](https://arxiv.org/abs/1804.109590)]) with the
    extension of direct training from raw sentences. SentencePiece allows us to
    make a purely end-to-end system that does not depend on language-specific
    pre/postprocessing.

extra:
  recipe-maintainers:
    - setu4993
    - rluria14
    - ndmaxar
    - oblute
    - h-vetinari
  feedstock-name: sentencepiece
